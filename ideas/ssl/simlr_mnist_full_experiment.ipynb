{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on docs:\n",
    "# https://docs.lightly.ai/self-supervised-learning/tutorials/package/tutorial_simclr_clothing.html\n",
    "\n",
    "# Also, see:\n",
    "# https://github.com/giakoumoglou/classification/blob/main/notebooks/main_simclr.ipynb\n",
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from lightly.data import LightlyDataset\n",
    "from lightly.transforms import SimCLRTransform, utils\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from utils import (\n",
    "    generate_embeddings,\n",
    "    prepare_mnist_images,\n",
    ")\n",
    "from models import SimCLRModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Using accelerator: gpu\n"
     ]
    }
   ],
   "source": [
    "# DEBUG\n",
    "# device = \"cpu\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "accelerator = \"gpu\" if device == \"cuda\" else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Using accelerator: {accelerator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input_size = 32  # laptop\n",
    "input_size = 128  # PC\n",
    "# batch_size = 64  # laptop\n",
    "batch_size = 256  # PC\n",
    "\n",
    "num_workers = 8\n",
    "seed = 1\n",
    "max_epochs = 20\n",
    "num_ftrs = 32\n",
    "\n",
    "path_to_data = Path(\"datasets/MNIST\")\n",
    "path_to_train_data = path_to_data / \"train\"\n",
    "path_to_test_data = path_to_data / \"test\"\n",
    "\n",
    "experiment_name = \"simclr_mnist\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the seed for our experiments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///d:/__repos/ml_concepts/ideas/ssl/mlruns/521104266412162370', creation_time=1719482649711, experiment_id='521104266412162370', last_update_time=1719482649711, lifecycle_stage='active', name='simclr_mnist', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config\n",
    "\n",
    "Here, we define the configuration for our experiment, to be logged in mlflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_list_of_lists = [[0, 4, 9], [0, 2, 4, 6, 9], [0, 1, 2, 4, 5, 7, 8]]\n",
    "initial_num_components_pca_list = [50, 20, 7, 3]\n",
    "embedding_sizes_list = [8, 16, 32, 512]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                 | Params\n",
      "---------------------------------------------------------\n",
      "0 | backbone        | Sequential           | 11.2 M\n",
      "1 | projection_head | SimCLRProjectionHead | 328 K \n",
      "2 | criterion       | NTXentLoss           | 0     \n",
      "---------------------------------------------------------\n",
      "11.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.5 M    Total params\n",
      "46.022    Total estimated model params size (MB)\n",
      "d:\\__repos\\ml_concepts\\venv\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:436: Consider setting `persistent_workers=True` in 'train_dataloader' to speed up the dataloader worker initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a53a74fecb84a65a31d4b4ea3683bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n",
      "torch.Size([256, 512, 1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\__repos\\ml_concepts\\venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] Nie można odnaleźć określonego pliku\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"d:\\__repos\\ml_concepts\\venv\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"C:\\Users\\Maciek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 501, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"C:\\Users\\Maciek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 966, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\Maciek\\AppData\\Local\\Programs\\Python\\Python310\\lib\\subprocess.py\", line 1435, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    }
   ],
   "source": [
    "for classes_list, initial_num_components_pca, embedding_size in product(\n",
    "    classes_list_of_lists, initial_num_components_pca_list, embedding_sizes_list\n",
    "):\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_param(\"classes_list\", classes_list)\n",
    "        mlflow.log_param(\"initial_num_components_pca\", initial_num_components_pca)\n",
    "        mlflow.log_param(\"embedding_size\", embedding_size)\n",
    "        mlflow.log_param(\"max_epochs\", max_epochs)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        \n",
    "        # Prepare the data\n",
    "        prepare_mnist_images(classes_list, path_to_data)\n",
    "\n",
    "        ## Train\n",
    "        train_transform = SimCLRTransform(\n",
    "            input_size=input_size, vf_prob=0.5, rr_prob=0.5)\n",
    "        train_dataset_simclr = LightlyDataset(\n",
    "            input_dir=path_to_train_data, transform=train_transform\n",
    "        )\n",
    "        dataloader_train_simclr = torch.utils.data.DataLoader(\n",
    "            train_dataset_simclr,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True,\n",
    "            num_workers=num_workers,\n",
    "        )\n",
    "        mlflow.log_metric(\"train_dataset_length\", (len(train_dataset_simclr)))\n",
    "\n",
    "        ## Test\n",
    "        test_transform = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize((input_size, input_size)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(\n",
    "                    mean=utils.IMAGENET_NORMALIZE[\"mean\"],\n",
    "                    std=utils.IMAGENET_NORMALIZE[\"std\"],\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        test_dataset_simclr = LightlyDataset(\n",
    "            input_dir=path_to_test_data, transform=test_transform\n",
    "        )\n",
    "        dataloader_test_simclr = torch.utils.data.DataLoader(\n",
    "            test_dataset_simclr,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=True,\n",
    "            num_workers=num_workers,\n",
    "        )\n",
    "        mlflow.log_metric(\"test_dataset_length\", (len(test_dataset_simclr)))\n",
    "        \n",
    "        # Create model and callbacks\n",
    "        model = SimCLRModel()\n",
    "        early_stopping_callback = EarlyStopping(\n",
    "            monitor=\"train_loss_ssl\", mode=\"min\", patience=5\n",
    "        )\n",
    "\n",
    "        model_checkpoint_callback = ModelCheckpoint(\n",
    "            monitor=\"train_loss_ssl\", mode=\"min\", save_top_k=-1\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        trainer = pl.Trainer(\n",
    "            log_every_n_steps=10,\n",
    "            max_epochs=max_epochs,\n",
    "            devices=1,\n",
    "            accelerator=accelerator,\n",
    "            callbacks=[early_stopping_callback, model_checkpoint_callback],\n",
    "            logger=CSVLogger(save_dir=\"lightning_logs\", name=experiment_name),\n",
    "        )\n",
    "        trainer.fit(model, dataloader_train_simclr)\n",
    "\n",
    "        # Generate embeddings\n",
    "        model.eval()\n",
    "        embeddings, filenames = generate_embeddings(model, dataloader_test_simclr)\n",
    "\n",
    "        # Visualize embeddings\n",
    "        pca = PCA(n_components=initial_num_components_pca)\n",
    "        data_pca = pca.fit_transform(embeddings.cpu().numpy())\n",
    "\n",
    "        tsne = TSNE(n_components=2)\n",
    "        data_tsne = tsne.fit_transform(data_pca)\n",
    "\n",
    "        targets = [int(fname.split(\"\\\\\")[0]) for fname in filenames]  # windows\n",
    "        os.makedirs(\"outputs\", exist_ok=True)\n",
    "        \n",
    "        # Save artifacts\n",
    "        explained_variance_ratio = pca.explained_variance_ratio_\n",
    "        explained_variance_path = f\"outputs/explained_variance_{classes_list}_{initial_num_components_pca}_{embedding_size}.png\"\n",
    "        plt.bar(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio, alpha=0.5, align='center')\n",
    "        plt.step(range(1, len(explained_variance_ratio) + 1), np.cumsum(explained_variance_ratio), where='mid')\n",
    "        plt.xlabel('Principal Component Index')\n",
    "        plt.ylabel('Explained Variance Ratio')\n",
    "        plt.title('PCA Explained Variance Ratio')\n",
    "        plt.savefig(explained_variance_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(explained_variance_path)\n",
    "\n",
    "        tsne_path = f\"outputs/tsne_{classes_list}_{initial_num_components_pca}_{embedding_size}.png\"\n",
    "        plt.scatter(data_tsne[:, 0], data_tsne[:, 1], c=targets, cmap=\"viridis\")\n",
    "        plt.title(\"t-SNE visualization\")\n",
    "        plt.colorbar()\n",
    "        plt.savefig(tsne_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(tsne_path)\n",
    "\n",
    "        pca_path = f\"outputs/pca_{classes_list}_{initial_num_components_pca}_{embedding_size}.png\"\n",
    "        plt.scatter(data_pca[:, 0], data_pca[:, 1], c=targets, cmap=\"viridis\")\n",
    "        plt.title(\"PCA visualization\")\n",
    "        plt.colorbar()\n",
    "        plt.savefig(pca_path)\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(pca_path)\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
