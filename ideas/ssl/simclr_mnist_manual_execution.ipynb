{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on docs:\n",
    "# https://docs.lightly.ai/self-supervised-learning/tutorials/package/tutorial_simclr_clothing.html\n",
    "\n",
    "# Also, see:\n",
    "# https://github.com/giakoumoglou/classification/blob/main/notebooks/main_simclr.ipynb\n",
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "from typing import Union, List, Tuple\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from lightly.data import LightlyDataset\n",
    "from lightly.transforms import SimCLRTransform, utils\n",
    "\n",
    "from utils import (\n",
    "    get_image_as_np_array,\n",
    "    plot_knn_clusters,\n",
    "    get_distance_between_points_in_cluster,\n",
    "    get_distances_between_centroids,\n",
    "    plot_clusters,\n",
    "    generate_embeddings_and_fnames_simclr,\n",
    "    check_labels_correspondence,\n",
    "    plot_knn_examples,\n",
    "    plot_clusters_3d,\n",
    "    generate_embeddings,\n",
    "    prepare_mnist_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "We set some configuration parameters for our experiment.\n",
    "Feel free to change them and analyze the effect.\n",
    "\n",
    "The default configuration with a batch size of 256 and input resolution of 128\n",
    "requires 6GB of GPU memory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# device = \"cpu\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "accelerator = \"gpu\" if device == \"cuda\" else \"cpu\"\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Using accelerator: {accelerator}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# input_size = 32  # laptop\n",
    "input_size = 128  # PC\n",
    "# batch_size = 64  # laptop\n",
    "batch_size = 256  # PC\n",
    "\n",
    "num_workers = 8\n",
    "seed = 1\n",
    "max_epochs = 100\n",
    "num_ftrs = 32\n",
    "\n",
    "path_to_data = Path(\"datasets/MNIST\")\n",
    "path_to_train_data = path_to_data / \"train\"\n",
    "path_to_test_data = path_to_data / \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the seed for our experiments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl.seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "We make sure MNIST dataset is downloaded and save only selected classes to .jpg files.\n",
    "This is to ensure to shuffiling problem arrises after unsupervised part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_mnist_images([0, 4, 9], path_to_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data augmentations and loaders\n",
    "\n",
    "We prepare data augmentations and loaders for unsupervised training, using lightly classes, like `SimCLRTransform` and `LightlyDataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_transform = SimCLRTransform(input_size=input_size, vf_prob=0.5, rr_prob=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_simclr = LightlyDataset(\n",
    "    input_dir=path_to_train_data, transform=train_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset_simclr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, target, fname = train_dataset_simclr[17111]\n",
    "print(\"sample\", sample)\n",
    "print(\"target\", target)\n",
    "print(\"fname\", fname)\n",
    "\n",
    "# targets got acquired weirdly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train_simclr = torch.utils.data.DataLoader(\n",
    "    train_dataset_simclr,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_example_idx = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader_train_simclr:\n",
    "    print(\"\\ngeneral batch info\")\n",
    "    print(type(batch))\n",
    "    print(len(batch))\n",
    "    print(type(batch[0]))\n",
    "    print(len(batch[0]))\n",
    "\n",
    "    print(\"\\nimage batch info\")\n",
    "    print(type(batch[0][0]))\n",
    "    print(batch[0][0].shape)\n",
    "    print(batch[0][1].shape)\n",
    "    plt.imshow(batch[0][0][train_example_idx].permute(1, 2, 0))\n",
    "\n",
    "    print(\"\\ntarget\")\n",
    "    print(type(batch[1][train_example_idx]))\n",
    "    print(batch[1][train_example_idx])\n",
    "\n",
    "    print(\"\\nfilename\")\n",
    "    print(type(batch[2][train_example_idx]))\n",
    "    print(batch[2][train_example_idx])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((input_size, input_size)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=utils.IMAGENET_NORMALIZE[\"mean\"],\n",
    "            std=utils.IMAGENET_NORMALIZE[\"std\"],\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_simclr = LightlyDataset(\n",
    "    input_dir=path_to_test_data, transform=test_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_dataset_simclr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, target, fname = test_dataset_simclr[1111]\n",
    "print(\"sample\", sample)\n",
    "print(\"target\", target)\n",
    "print(\"fname\", fname)\n",
    "# so the targets are correct here - they are just sequential, instead of infered from dir names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test_simclr = torch.utils.data.DataLoader(\n",
    "    test_dataset_simclr,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in dataloader_test_simclr:\n",
    "    print(\"\\ngeneral batch info\")\n",
    "    print(type(batch))\n",
    "    print(len(batch))\n",
    "    print(type(batch[0]))\n",
    "    print(len(batch[0]))\n",
    "\n",
    "    print(\"\\nimage batch info\")\n",
    "    print(type(batch[0][0]))\n",
    "    print(batch[0][33].shape)\n",
    "    print(batch[0][33].shape)\n",
    "    plt.imshow(batch[0][33].permute(1, 2, 0))\n",
    "\n",
    "    print(\"\\ntarget\")\n",
    "    print(type(batch[1][33]))\n",
    "    print(batch[1][33])\n",
    "\n",
    "    print(\"\\nfilename\")\n",
    "    print(type(batch[2][33]))\n",
    "    print(batch[2][33])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the SimCLR Model\n",
    "Now we create the SimCLR model. We implement it as a PyTorch Lightning Module\n",
    "and use a ResNet-18 backbone from Torchvision. Lightly provides implementations\n",
    "of the SimCLR projection head and loss function in the `SimCLRProjectionHead`\n",
    "and `NTXentLoss` classes. We can simply import them and combine the building\n",
    "blocks in the module.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lightly.loss import NTXentLoss\n",
    "from lightly.models.modules.heads import SimCLRProjectionHead\n",
    "\n",
    "\n",
    "class SimCLRModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = torchvision.models.resnet18()\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "\n",
    "        hidden_dim = resnet.fc.in_features\n",
    "        self.projection_head = SimCLRProjectionHead(hidden_dim, hidden_dim, 64)\n",
    "        # output_dim = 128 -> embeddings.shape = 512\n",
    "        # output_dim = 64 -> embeddings.shape = 512\n",
    "        # because backbone output is 512, and this works every time\n",
    "        self.criterion = NTXentLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(h)\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x0, x1), _, _ = batch\n",
    "        z0 = self.forward(x0)\n",
    "        z1 = self.forward(x1)\n",
    "        loss = self.criterion(z0, z1)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(\n",
    "            self.parameters(), lr=6e-2, momentum=0.9, weight_decay=5e-4\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the module using the PyTorch Lightning Trainer on a single GPU.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SimCLRModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"train_loss_ssl\", mode=\"min\", patience=5\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"train_loss_ssl\", mode=\"min\", save_top_k=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    log_every_n_steps=10,\n",
    "    max_epochs=4,\n",
    "    # max_epochs=max_epochs,\n",
    "    devices=1,\n",
    "    accelerator=accelerator,\n",
    "    callbacks=[early_stopping_callback, model_checkpoint_callback],\n",
    "    logger=CSVLogger(save_dir=\"lightning_logs\", name=\"simclr_mnist\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.fit(model, dataloader_train_simclr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a helper function to generate embeddings\n",
    "from our test images using the model we just trained.\n",
    "Note that only the backbone is needed to generate embeddings,\n",
    "the projection head is only required for the training.\n",
    "Make sure to put the model into eval mode for this part!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For eval only\n",
    "\n",
    "# PC-trained model\n",
    "# model = SimCLRModel.load_from_checkpoint(\n",
    "#     \"./lightning_logs/old_stuff/version_38/checkpoints/epoch=16-step=1173.ckpt\"\n",
    "# )\n",
    "\n",
    "model = SimCLRModel.load_from_checkpoint(\n",
    "    \"./lightning_logs/simclr_mnist/version_4/checkpoints/epoch=3-step=276.ckpt\"\n",
    ")\n",
    "\n",
    "# laptop-trained model\n",
    "# maybe not-OK, as it was trained on 70k images (both train and test)\n",
    "# model = SimCLRModel.load_from_checkpoint(\n",
    "#     \"./lightning_logs/version_0/checkpoints/epoch=9-step=10930.ckpt\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use train dataloader for now\n",
    "embeddings, filenames = generate_embeddings(model, dataloader_test_simclr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"embeddings\")\n",
    "print(type(embeddings))\n",
    "print(embeddings.shape)\n",
    "\n",
    "print(\"filenames\")\n",
    "print(type(filenames))\n",
    "print(len(filenames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings[0].max())\n",
    "print(embeddings[0].min())\n",
    "print(embeddings[0].mean())\n",
    "print(embeddings[0].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings[0].histogram())\n",
    "hist, bin_edges = embeddings[0].histogram(bins=100)\n",
    "plt.bar(bin_edges[:-1], hist, width=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filenames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Will basically consist of 2 steps:\n",
    "1. Dimensionality reduction (UMAP, PCA or t-SNE)\n",
    "2. Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=50)\n",
    "data_pca = pca.fit_transform(embeddings.cpu().numpy())\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "data_tsne = tsne.fit_transform(data_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "clusters_tsne = kmeans.fit_predict(data_tsne)\n",
    "clusters_pca = kmeans.fit_predict(data_pca)\n",
    "\n",
    "unique, counts = np.unique(clusters_tsne, return_counts=True)\n",
    "print(\"TSNE\")\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(clusters_pca, return_counts=True)\n",
    "print(\"PCA\")\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames[0].split(\"\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [int(fname.split(\"\\\\\")[0]) for fname in filenames]  # windows\n",
    "print(len(targets))\n",
    "print(targets[:10])\n",
    "print(targets[1300:1310])\n",
    "print(targets[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_tsne[:, 0], data_tsne[:, 1], c=targets, cmap=\"viridis\")\n",
    "plt.title(\"t-SNE visualization\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_pca[:, 48], data_pca[:, 49], c=targets, cmap=\"viridis\")\n",
    "plt.title(\"PCA visualization\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
